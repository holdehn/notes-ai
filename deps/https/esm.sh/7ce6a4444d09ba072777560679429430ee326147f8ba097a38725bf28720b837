/* esm.sh - esbuild bundle(langchain@0.0.52/llms/openai) deno production */
import __Process$ from "https://deno.land/std@0.177.0/node/process.ts";var Ne=Object.defineProperty;var p=(n,e)=>()=>(n&&(e=n(n=0)),e);var ce=(n,e)=>{for(var r in e)Ne(n,r,{get:e[r],enumerable:!0})};async function he(n,e){let r=n.getReader(),t;for(;!(t=await r.read()).done;)e(t.value)}function pe(n){let e,r,t,s=!1;return function(o){e===void 0?(e=o,r=0,t=-1):e=Me(e,o);let i=e.length,l=0;for(;r<i;){s&&(e[r]===10&&(l=++r),s=!1);let h=-1;for(;r<i&&h===-1;++r)switch(e[r]){case 58:t===-1&&(t=r-l);break;case 13:s=!0;case 10:h=r;break}if(h===-1)break;n(e.subarray(l,h),t),l=r,t=-1}l===i?e=void 0:l!==0&&(e=e.subarray(l),r-=l)}}function de(n,e,r){let t=ue(),s=new TextDecoder;return function(o,i){if(o.length===0)n?.(t),t=ue();else if(i>0){let l=s.decode(o.subarray(0,i)),h=i+(o[i+1]===32?2:1),c=s.decode(o.subarray(h));switch(l){case"data":t.data=t.data?t.data+`
`+c:c;break;case"event":t.event=c;break;case"id":e?.(t.id=c);break;case"retry":{let u=parseInt(c,10);Number.isNaN(u)||r?.(t.retry=u);break}}}}}function Me(n,e){let r=new Uint8Array(n.length+e.length);return r.set(n),r.set(e,n.length),r}function ue(){return{data:"",event:"",id:"",retry:void 0}}var $,me=p(()=>{$="text/event-stream"});import I from"/v118/axios@1.4.0/deno/axios.mjs";function Se(n,e,r){let{validateStatus:t}=r.config;!r.status||!t||t(r.status)?n(r):e(ye(`Request failed with status code ${r.status}`,r.config,null,r.request,r))}function $e(n){return/^([a-z][a-z\d+\-.]*:)?\/\//i.test(n)}function Ie(n,e){return e?n.replace(/\/+$/,"")+"/"+e.replace(/^\/+/,""):n}function fe(n){return encodeURIComponent(n).replace(/%3A/gi,":").replace(/%24/g,"$").replace(/%2C/gi,",").replace(/%20/g,"+").replace(/%5B/gi,"[").replace(/%5D/gi,"]")}function Re(n,e,r){if(!e)return n;var t;if(r)t=r(e);else if(Ue(e))t=e.toString();else{var s=[];be(e,function(i,l){i===null||typeof i>"u"||(ge(i)?l=`${l}[]`:i=[i],be(i,function(c){ze(c)?c=c.toISOString():qe(c)&&(c=JSON.stringify(c)),s.push(`${fe(l)}=${fe(c)}`)}))}),t=s.join("&")}if(t){var a=n.indexOf("#");a!==-1&&(n=n.slice(0,a)),n+=(n.indexOf("?")===-1?"?":"&")+t}return n}function De(n,e){return n&&!$e(e)?Ie(n,e):e}function Ke(n){return typeof n>"u"}function qe(n){return n!==null&&typeof n=="object"}function ze(n){return toString.call(n)==="[object Date]"}function Ue(n){return toString.call(n)==="[object URLSearchParams]"}function ge(n){return Array.isArray(n)}function be(n,e){if(!(n===null||typeof n>"u"))if(typeof n!="object"&&(n=[n]),ge(n))for(var r=0,t=n.length;r<t;r++)e.call(null,n[r],r,n);else for(var s in n)Object.prototype.hasOwnProperty.call(n,s)&&e.call(null,n[s],s,n)}function We(n){return toString.call(n)==="[object FormData]"}function He(){return typeof navigator<"u"&&(navigator.product==="ReactNative"||navigator.product==="NativeScript"||navigator.product==="NS")?!1:typeof document<"u"&&typeof document<"u"}async function x(n){let e=Fe(n),r=await Ve(e,n);return new Promise((t,s)=>{r instanceof Error?s(r):Object.prototype.toString.call(n.settle)==="[object Function]"?n.settle(t,s,r):Se(t,s,r)})}async function Ve(n,e){let r;try{r=await fetch(n)}catch{return ye("Network Error",e,"ERR_NETWORK",n)}let t={ok:r.ok,status:r.status,statusText:r.statusText,headers:new Headers(r.headers),config:e,request:n};if(r.status>=200&&r.status!==204)if(e.responseType==="stream"){let s=r.headers.get("content-type");if(!s?.startsWith($))throw new Error(`Expected content-type to be ${$}, Actual: ${s}`);await he(r.body,pe(de(e.onmessage)))}else switch(e.responseType){case"arraybuffer":t.data=await r.arrayBuffer();break;case"blob":t.data=await r.blob();break;case"json":t.data=await r.json();break;case"formData":t.data=await r.formData();break;default:t.data=await r.text();break}return t}function Fe(n){let e=new Headers(n.headers);if(n.auth){let o=n.auth.username||"",i=n.auth.password?decodeURI(encodeURIComponent(n.auth.password)):"";e.set("Authorization",`Basic ${btoa(`${o}:${i}`)}`)}let r=n.method.toUpperCase(),t={headers:e,method:r};r!=="GET"&&r!=="HEAD"&&(t.body=n.data,We(t.body)&&He()&&e.delete("Content-Type")),n.mode&&(t.mode=n.mode),n.cache&&(t.cache=n.cache),n.integrity&&(t.integrity=n.integrity),n.redirect&&(t.redirect=n.redirect),n.referrer&&(t.referrer=n.referrer),n.timeout&&n.timeout>0&&(t.signal=AbortSignal.timeout(n.timeout)),n.signal&&(t.signal=n.signal),Ke(n.withCredentials)||(t.credentials=n.withCredentials?"include":"omit"),n.responseType==="stream"&&t.headers.set("Accept",$);let s=De(n.baseURL,n.url),a=Re(s,n.params,n.paramsSerializer);return new Request(a,t)}function ye(n,e,r,t,s){if(I.AxiosError&&typeof I.AxiosError=="function")return new I.AxiosError(n,I.AxiosError[r],e,t,s);let a=new Error(n);return Be(a,e,r,t,s)}function Be(n,e,r,t,s){return n.config=e,r&&(n.code=r),n.request=t,n.response=s,n.isAxiosError=!0,n.toJSON=function(){return{message:this.message,name:this.name,description:this.description,number:this.number,fileName:this.fileName,lineNumber:this.lineNumber,columnNumber:this.columnNumber,stack:this.stack,config:this.config,code:this.code,status:this.response&&this.response.status?this.response.status:null}},n}var R=p(()=>{me()});var B,we=p(()=>{B=(n,e)=>n.reduce((r,t,s)=>{let a=Math.floor(s/e),o=r[a]||[];return r[a]=o.concat([t]),r},[])});import Je from"/v118/object-hash@3.0.0/deno/object-hash.mjs";var _e,J,Ge,v,Pe=p(()=>{_e=(...n)=>Je(n.join("_")),J=class{},Ge=new Map,v=class extends J{constructor(e){super(),Object.defineProperty(this,"cache",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.cache=e??new Map}lookup(e,r){return Promise.resolve(this.cache.get(_e(e,r))??null)}async update(e,r,t){this.cache.set(_e(e,r),t)}static global(){return new v(Ge)}}});var G,_,Y,A,j,D=p(()=>{G=class{},_=class extends G{constructor(e){super(),Object.defineProperty(this,"alwaysVerbose",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"ignoreLLM",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"ignoreChain",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"ignoreAgent",{enumerable:!0,configurable:!0,writable:!0,value:!1}),e&&(this.alwaysVerbose=e.alwaysVerbose??this.alwaysVerbose,this.ignoreLLM=e.ignoreLLM??this.ignoreLLM,this.ignoreChain=e.ignoreChain??this.ignoreChain,this.ignoreAgent=e.ignoreAgent??this.ignoreAgent)}},Y=class extends _{setHandler(e){return this.setHandlers([e])}},A=class extends Y{constructor(){super(),Object.defineProperty(this,"handlers",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.handlers=[]}async handleLLMStart(e,r,t){await Promise.all(this.handlers.map(async s=>{if(!s.ignoreLLM&&(t||s.alwaysVerbose))try{await s.handleLLMStart?.(e,r)}catch(a){console.error(`Error in handler ${s.constructor.name}, handleLLMStart: ${a}`)}}))}async handleLLMNewToken(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreLLM&&(r||t.alwaysVerbose))try{await t.handleLLMNewToken?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleLLMNewToken: ${s}`)}}))}async handleLLMError(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreLLM&&(r||t.alwaysVerbose))try{await t.handleLLMError?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleLLMError: ${s}`)}}))}async handleLLMEnd(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreLLM&&(r||t.alwaysVerbose))try{await t.handleLLMEnd?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleLLMEnd: ${s}`)}}))}async handleChainStart(e,r,t){await Promise.all(this.handlers.map(async s=>{if(!s.ignoreChain&&(t||s.alwaysVerbose))try{await s.handleChainStart?.(e,r)}catch(a){console.error(`Error in handler ${s.constructor.name}, handleChainStart: ${a}`)}}))}async handleChainError(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreChain&&(r||t.alwaysVerbose))try{await t.handleChainError?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleChainError: ${s}`)}}))}async handleChainEnd(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreChain&&(r||t.alwaysVerbose))try{await t.handleChainEnd?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleChainEnd: ${s}`)}}))}async handleToolStart(e,r,t){await Promise.all(this.handlers.map(async s=>{if(!s.ignoreAgent&&(t||s.alwaysVerbose))try{await s.handleToolStart?.(e,r)}catch(a){console.error(`Error in handler ${s.constructor.name}, handleToolStart: ${a}`)}}))}async handleToolError(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreAgent&&(r||t.alwaysVerbose))try{await t.handleToolError?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleToolError: ${s}`)}}))}async handleToolEnd(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreAgent&&(r||t.alwaysVerbose))try{await t.handleToolEnd?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleToolEnd: ${s}`)}}))}async handleText(e,r){await Promise.all(this.handlers.map(async t=>{if(r||t.alwaysVerbose)try{await t.handleText?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleText: ${s}`)}}))}async handleAgentAction(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreAgent&&(r||t.alwaysVerbose))try{await t.handleAgentAction?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleAgentAction: ${s}`)}}))}async handleAgentEnd(e,r){await Promise.all(this.handlers.map(async t=>{if(!t.ignoreAgent&&(r||t.alwaysVerbose))try{await t.handleAgentEnd?.(e)}catch(s){console.error(`Error in handler ${t.constructor.name}, handleAgentEnd: ${s}`)}}))}addHandler(e){this.handlers.push(e)}removeHandler(e){this.handlers=this.handlers.filter(r=>r!==e)}setHandlers(e){this.handlers=e}static fromHandlers(e){class r extends _{constructor(){super(),Object.defineProperty(this,"alwaysVerbose",{enumerable:!0,configurable:!0,writable:!0,value:!0}),Object.assign(this,e)}}let t=new this;return t.addHandler(new r),t}},j=class extends _{async handleChainStart(e){console.log(`Entering new ${e.name} chain...`)}async handleChainEnd(e){console.log("Finished chain.")}async handleAgentAction(e){console.log(e.log)}async handleToolEnd(e){console.log(e)}async handleText(e){console.log(e)}async handleAgentEnd(e){console.log(e.log)}}});var Q,C,X=p(()=>{D();Q=class extends _{constructor(){super(),Object.defineProperty(this,"session",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stack",{enumerable:!0,configurable:!0,writable:!0,value:[]}),Object.defineProperty(this,"executionOrder",{enumerable:!0,configurable:!0,writable:!0,value:1}),this.alwaysVerbose=!0}async newSession(e){let r={start_time:Date.now(),name:e},t=await this.persistSession(r);return this.session=t,t}_addChildRun(e,r){if(r.type==="llm")e.child_llm_runs.push(r);else if(r.type==="chain")e.child_chain_runs.push(r);else if(r.type==="tool")e.child_tool_runs.push(r);else throw new Error("Invalid run type")}_startTrace(e){if(this.executionOrder+=1,this.stack.length>0){if(!(this.stack.at(-1)?.type==="tool"||this.stack.at(-1)?.type==="chain"))throw new Error("Nested run can only be logged for tool or chain");let r=this.stack.at(-1);this._addChildRun(r,e)}this.stack.push(e)}async _endTrace(){let e=this.stack.pop();this.stack.length===0&&e&&(this.executionOrder=1,await this.persistRun(e))}async handleLLMStart(e,r,t){this.session===void 0&&(this.session=await this.loadDefaultSession());let s={start_time:Date.now(),end_time:0,serialized:e,prompts:r,session_id:this.session.id,execution_order:this.executionOrder,type:"llm"};this._startTrace(s)}async handleLLMEnd(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="llm")throw new Error("No LLM run to end.");let t=this.stack.at(-1);t.end_time=Date.now(),t.response=e,await this._endTrace()}async handleLLMError(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="llm")throw new Error("No LLM run to end.");let t=this.stack.at(-1);t.end_time=Date.now(),t.error=e.message,await this._endTrace()}async handleChainStart(e,r,t){this.session===void 0&&(this.session=await this.loadDefaultSession());let s={start_time:Date.now(),end_time:0,serialized:e,inputs:r,session_id:this.session.id,execution_order:this.executionOrder,type:"chain",child_llm_runs:[],child_chain_runs:[],child_tool_runs:[]};this._startTrace(s)}async handleChainEnd(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="chain")throw new Error("No chain run to end.");let t=this.stack.at(-1);t.end_time=Date.now(),t.outputs=e,await this._endTrace()}async handleChainError(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="chain")throw new Error("No chain run to end.");let t=this.stack.at(-1);t.end_time=Date.now(),t.error=e.message,await this._endTrace()}async handleToolStart(e,r,t){this.session===void 0&&(this.session=await this.loadDefaultSession());let s={start_time:Date.now(),end_time:0,serialized:e,tool_input:r,session_id:this.session.id,execution_order:this.executionOrder,type:"tool",action:JSON.stringify(e),child_llm_runs:[],child_chain_runs:[],child_tool_runs:[]};this._startTrace(s)}async handleToolEnd(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="tool")throw new Error("No tool run to end");let t=this.stack.at(-1);t.end_time=Date.now(),t.output=e,await this._endTrace()}async handleToolError(e,r){if(this.stack.length===0||this.stack.at(-1)?.type!=="tool")throw new Error("No tool run to end.");let t=this.stack.at(-1);t.end_time=Date.now(),t.error=e.message,await this._endTrace()}},C=class extends Q{constructor(){super(),Object.defineProperty(this,"endpoint",{enumerable:!0,configurable:!0,writable:!0,value:(typeof __Process$<"u"?__Process$.env.LANGCHAIN_ENDPOINT:void 0)||"http://localhost:8000"}),Object.defineProperty(this,"headers",{enumerable:!0,configurable:!0,writable:!0,value:{"Content-Type":"application/json"}}),typeof __Process$<"u"&&__Process$.env.LANGCHAIN_API_KEY&&(this.headers["x-api-key"]=__Process$.env.LANGCHAIN_API_KEY)}async persistRun(e){let r;e.type==="llm"?r=`${this.endpoint}/llm-runs`:e.type==="chain"?r=`${this.endpoint}/chain-runs`:r=`${this.endpoint}/tool-runs`;let t=await fetch(r,{method:"POST",headers:this.headers,body:JSON.stringify(e)});t.ok||console.error(`Failed to persist run: ${t.status} ${t.statusText}`)}async persistSession(e){let r=`${this.endpoint}/sessions`,t=await fetch(r,{method:"POST",headers:this.headers,body:JSON.stringify(e)});return t.ok?{id:(await t.json()).id,...e}:(console.error(`Failed to persist session: ${t.status} ${t.statusText}, using default session.`),{id:1,...e})}async loadSession(e){let r=`${this.endpoint}/sessions?name=${e}`;return this._handleSessionResponse(r)}async loadDefaultSession(){let e=`${this.endpoint}/sessions?name=default`;return this._handleSessionResponse(e)}async _handleSessionResponse(e){let r=await fetch(e,{method:"GET",headers:this.headers}),t;if(!r.ok)return console.error(`Failed to load session: ${r.status} ${r.statusText}`),t={id:1,start_time:Date.now()},this.session=t,t;let s=await r.json();return s.length===0?(t={id:1,start_time:Date.now()},this.session=t,t):([t]=s,this.session=t,t)}}});function Z(){return y.getInstance()}var y,xe=p(()=>{X();D();y=class extends A{constructor(){super()}static getInstance(){return y.instance||(y.instance=new y,y.instance.addHandler(new j),typeof __Process$<"u"&&__Process$.env.LANGCHAIN_HANDLER==="langchain"&&y.instance.addHandler(new C)),y.instance}}});var ke=p(()=>{D();X();xe()});import Ye from"/v118/p-retry@4.6.2/deno/p-retry.mjs";import ee from"/v118/p-queue@6.6.2/deno/p-queue.mjs";var K,ve=p(()=>{K=class{constructor(e){Object.defineProperty(this,"maxConcurrency",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"maxRetries",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"queue",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.maxConcurrency=e.maxConcurrency??1/0,this.maxRetries=e.maxRetries??6;let r="default"in ee?ee.default:ee;this.queue=new r({concurrency:this.maxConcurrency})}call(e,...r){return this.queue.add(()=>Ye(()=>e(...r).catch(t=>{throw t instanceof Error?t:new Error(t)}),{retries:this.maxRetries,randomize:!0}),{throwOnTimeout:!0})}}});var k,Qe,te,Te,q=p(()=>{k=n=>n.startsWith("gpt-3.5-turbo-")?"gpt-3.5-turbo":n.startsWith("gpt-4-32k-")?"gpt-4-32k":n.startsWith("gpt-4-")?"gpt-4":n,Qe=n=>{switch(k(n)){case"text-davinci-003":return 4097;case"text-curie-001":return 2048;case"text-babbage-001":return 2048;case"text-ada-001":return 2048;case"code-davinci-002":return 8e3;case"code-cushman-001":return 2048;default:return 4097}},te=async()=>{try{let{encoding_for_model:n}=await import("/v118/@dqbd/tiktoken@1.0.7/deno/tiktoken.mjs");return{encoding_for_model:n}}catch(n){return console.log(n),{encoding_for_model:null}}},Te=async({prompt:n,modelName:e})=>{let{encoding_for_model:r}=await te(),t=Math.ceil(n.length/4);try{if(r){let a=r(k(e));t=a.encode(n).length,a.free()}}catch(a){console.warn("Failed to calculate number of tokens with tiktoken, falling back to approximate count",a)}return Qe(e)-t}});var T,z,N,U,W,re=p(()=>{T=class{constructor(e){Object.defineProperty(this,"text",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"name",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.text=e}},z=class extends T{_getType(){return"human"}},N=class extends T{_getType(){return"ai"}},U=class extends T{_getType(){return"system"}},W=class extends T{constructor(e,r){super(e),Object.defineProperty(this,"role",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.role=r}_getType(){return"generic"}}});function Oe(n,e="Human",r="AI"){let t=[];for(let s of n){let a;if(s._getType()==="human")a=e;else if(s._getType()==="ai")a=r;else if(s._getType()==="system")a="System";else if(s._getType()==="generic")a=s.role;else throw new Error(`Got unsupported message type: ${s}`);t.push(`${a}: ${s.text}`)}return t.join(`
`)}var Ee=p(()=>{});var H,Le=p(()=>{re();ne();Ee();H=class extends O{constructor({...e}){super(e)}async generate(e,r){let t=[],s=[],a=e.map(i=>Oe(i));await this.callbackManager.handleLLMStart({name:this._llmType()},a,this.verbose);try{for(let i of e){let l=await this._generate(i,r);l.llmOutput&&s.push(l.llmOutput),t.push(l.generations)}}catch(i){throw await this.callbackManager.handleLLMError(i,this.verbose),i}let o={generations:t,llmOutput:s.length?this._combineLLMOutput?.(...s):void 0};return await this.callbackManager.handleLLMEnd(o,this.verbose),o}_modelType(){return"base_chat_model"}async generatePrompt(e,r){let t=e.map(s=>s.toChatMessages());return this.generate(t,r)}async call(e,r){return(await this.generate([e],r)).generations[0][0].message}async callPrompt(e,r){let t=e.toChatMessages();return this.call(t,r)}}});var Ae={};ce(Ae,{ChatOpenAI:()=>se});import{Configuration as Xe,OpenAIApi as Ze}from"/v118/openai@3.2.1/deno/openai.mjs";function et(n){switch(n){case"system":return"system";case"ai":return"assistant";case"human":return"user";default:throw new Error(`Unknown message type: ${n}`)}}function tt(n,e){switch(n){case"user":return new z(e);case"assistant":return new N(e);case"system":return new U(e);default:return new W(e,n??"unknown")}}var se,je=p(()=>{R();Le();re();q();se=class extends H{constructor(e,r){super(e??{}),Object.defineProperty(this,"temperature",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"topP",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"frequencyPenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"presencePenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"n",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"logitBias",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelName",{enumerable:!0,configurable:!0,writable:!0,value:"gpt-3.5-turbo"}),Object.defineProperty(this,"modelKwargs",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stop",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"timeout",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"streaming",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"maxTokens",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"clientConfig",{enumerable:!0,configurable:!0,writable:!0,value:void 0});let t=e?.openAIApiKey??(typeof __Process$<"u"?__Process$.env.OPENAI_API_KEY:void 0);if(!t)throw new Error("OpenAI API key not found");if(this.modelName=e?.modelName??this.modelName,this.modelKwargs=e?.modelKwargs??{},this.timeout=e?.timeout,this.temperature=e?.temperature??this.temperature,this.topP=e?.topP??this.topP,this.frequencyPenalty=e?.frequencyPenalty??this.frequencyPenalty,this.presencePenalty=e?.presencePenalty??this.presencePenalty,this.maxTokens=e?.maxTokens,this.n=e?.n??this.n,this.logitBias=e?.logitBias,this.stop=e?.stop,this.streaming=e?.streaming??!1,this.streaming&&this.n>1)throw new Error("Cannot stream results when n > 1");this.clientConfig={apiKey:t,...r}}invocationParams(){return{model:this.modelName,temperature:this.temperature,top_p:this.topP,frequency_penalty:this.frequencyPenalty,presence_penalty:this.presencePenalty,max_tokens:this.maxTokens,n:this.n,logit_bias:this.logitBias,stop:this.stop,stream:this.streaming,...this.modelKwargs}}_identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}identifyingParams(){return this._identifyingParams()}async _generate(e,r){let t={};if(this.stop&&r)throw new Error("Stop found in input and default params");let s=this.invocationParams();s.stop=r??s.stop;let a=e.map(u=>({role:et(u._getType()),content:u.text,name:u.name})),o=s.stream?await new Promise((u,d)=>{let m,S=!1;this.completionWithRetry({...s,messages:a},{responseType:"stream",onmessage:g=>{if(g.data?.trim?.()==="[DONE]")u(m);else{let w=JSON.parse(g.data);m||(m={id:w.id,object:w.object,created:w.created,model:w.model,choices:[]});let f=w.choices[0];if(f!=null){let b=m.choices.find(P=>P.index===f.index);b||(b={index:f.index,finish_reason:f.finish_reason??void 0},m.choices.push(b)),b.message||(b.message={role:f.delta?.role,content:f.delta?.content??""}),b.message.content+=f.delta?.content??"",this.callbackManager.handleLLMNewToken(f.delta?.content??"",!0)}}}}).catch(g=>{S||(S=!0,d(g))})}):await this.completionWithRetry({...s,messages:a}),{completion_tokens:i,prompt_tokens:l,total_tokens:h}=o.usage??{};i&&(t.completionTokens=(t.completionTokens??0)+i),l&&(t.promptTokens=(t.promptTokens??0)+l),h&&(t.totalTokens=(t.totalTokens??0)+h);let c=[];for(let u of o.choices){let d=u.message?.role??void 0,m=u.message?.content??"";c.push({text:m,message:tt(d,m)})}return{generations:c,llmOutput:{tokenUsage:t}}}async getNumTokensFromMessages(e){let r=0,t=0,s=0;k(this.modelName)==="gpt-3.5-turbo"?(t=4,s=-1):k(this.modelName).startsWith("gpt-4")&&(t=3,s=1);let a=await Promise.all(e.map(async o=>{let l=await this.getNumTokens(o.text)+t+(o.name?s:0);return r+=l,l}));return{totalCount:r,countPerMessage:a}}async completionWithRetry(e,r){if(!this.client){let t=new Xe({...this.clientConfig,baseOptions:{timeout:this.timeout,adapter:x,...this.clientConfig.baseOptions}});this.client=new Ze(t)}return this.caller.call(this.client.createChatCompletion.bind(this.client),e,r).then(t=>t.data)}_llmType(){return"openai"}_combineLLMOutput(...e){return e.reduce((r,t)=>(t&&t.tokenUsage&&(r.tokenUsage.completionTokens+=t.tokenUsage.completionTokens??0,r.tokenUsage.promptTokens+=t.tokenUsage.promptTokens??0,r.tokenUsage.totalTokens+=t.tokenUsage.totalTokens??0),r),{tokenUsage:{completionTokens:0,promptTokens:0,totalTokens:0}})}}});var rt,O,ne=p(()=>{ke();ve();q();rt=()=>!1,O=class{constructor(e){Object.defineProperty(this,"verbose",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"callbackManager",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"caller",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"_encoding",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"_registry",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.verbose=e.verbose??(e.callbackManager?!0:rt()),this.callbackManager=e.callbackManager??Z(),this.caller=new K(e??{})}async getNumTokens(e){let r=Math.ceil(e.length/4);try{if(!this._encoding){let{encoding_for_model:t}=await te();t&&(this._encoding=t("modelName"in this?k(this.modelName):"gpt2"),this._registry=new FinalizationRegistry(s=>s.free()),this._registry.register(this,this._encoding))}this._encoding&&(r=this._encoding.encode(e).length)}catch(t){console.warn("Failed to calculate number of tokens with tiktoken, falling back to approximate count",t)}return r}_identifyingParams(){return{}}serialize(){return{...this._identifyingParams(),_type:this._llmType(),_model:this._modelType()}}static async deserialize(e){let{_type:r,_model:t,...s}=e;if(t&&t!=="base_chat_model")throw new Error(`Cannot load LLM with model ${t}`);let a={openai:(await Promise.resolve().then(()=>(je(),Ae))).ChatOpenAI}[r];if(a===void 0)throw new Error(`Cannot load  LLM with type ${r}`);return new a(s)}}});var M,V,ae=p(()=>{Pe();ne();M=class extends O{constructor({cache:e,concurrency:r,...t}){super(r?{maxConcurrency:r,...t}:t),Object.defineProperty(this,"name",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"cache",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),typeof e=="object"?this.cache=e:e?this.cache=v.global():this.cache=void 0}async generatePrompt(e,r){let t=e.map(s=>s.toString());return this.generate(t,r)}async _generateUncached(e,r){await this.callbackManager.handleLLMStart({name:this._llmType()},e,this.verbose);let t;try{t=await this._generate(e,r)}catch(s){throw await this.callbackManager.handleLLMError(s,this.verbose),s}return await this.callbackManager.handleLLMEnd(t,this.verbose),t}async generate(e,r){if(!Array.isArray(e))throw new Error("Argument 'prompts' is expected to be a string[]");if(!this.cache)return this._generateUncached(e,r);let{cache:t}=this,s=this.serialize();s.stop=r;let a=`${Object.entries(s).sort()}`,o=[],i=await Promise.all(e.map(async(h,c)=>{let u=await t.lookup(h,a);return u||o.push(c),u})),l={};if(o.length>0){let h=await this._generateUncached(o.map(c=>e[c]),r);await Promise.all(h.generations.map(async(c,u)=>{let d=o[u];return i[d]=c,t.update(e[d],a,c)})),l=h.llmOutput??{}}return{generations:i,llmOutput:l}}async call(e,r){let{generations:t}=await this.generate([e],r);return t[0][0].text}_identifyingParams(){return{}}serialize(){return{...this._identifyingParams(),_type:this._llmType(),_model:this._modelType()}}_modelType(){return"base_llm"}static async deserialize(e){let{_type:r,_model:t,...s}=e;if(t&&t!=="base_llm")throw new Error(`Cannot load LLM with model ${t}`);let a={openai:(await Promise.resolve().then(()=>(ie(),Ce))).OpenAI}[r];if(a===void 0)throw new Error(`Cannot load  LLM with type ${r}`);return new a(s)}},V=class extends M{async _generate(e,r){let t=[];for(let s=0;s<e.length;s+=1){let a=await this._call(e[s],r);t.push([{text:a}])}return{generations:t}}}});import{Configuration as nt,OpenAIApi as st}from"/v118/openai@3.2.1/deno/openai.mjs";var E,oe=p(()=>{R();ae();E=class extends V{constructor(e,r){super(e??{}),Object.defineProperty(this,"temperature",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"topP",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"frequencyPenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"presencePenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"n",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"logitBias",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"maxTokens",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelName",{enumerable:!0,configurable:!0,writable:!0,value:"gpt-3.5-turbo"}),Object.defineProperty(this,"prefixMessages",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelKwargs",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"timeout",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stop",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"streaming",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"clientConfig",{enumerable:!0,configurable:!0,writable:!0,value:void 0});let t=e?.openAIApiKey??(typeof __Process$<"u"?__Process$.env.OPENAI_API_KEY:void 0);if(!t)throw new Error("OpenAI API key not found");if(this.modelName=e?.modelName??this.modelName,this.prefixMessages=e?.prefixMessages??this.prefixMessages,this.modelKwargs=e?.modelKwargs??{},this.timeout=e?.timeout,this.temperature=e?.temperature??this.temperature,this.topP=e?.topP??this.topP,this.frequencyPenalty=e?.frequencyPenalty??this.frequencyPenalty,this.presencePenalty=e?.presencePenalty??this.presencePenalty,this.n=e?.n??this.n,this.logitBias=e?.logitBias,this.maxTokens=e?.maxTokens,this.stop=e?.stop,this.streaming=e?.streaming??!1,this.streaming&&this.n>1)throw new Error("Cannot stream results when n > 1");this.clientConfig={apiKey:t,...r}}invocationParams(){return{model:this.modelName,temperature:this.temperature,top_p:this.topP,frequency_penalty:this.frequencyPenalty,presence_penalty:this.presencePenalty,n:this.n,logit_bias:this.logitBias,max_tokens:this.maxTokens,stop:this.stop,stream:this.streaming,...this.modelKwargs}}_identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}formatMessages(e){let r={role:"user",content:e};return this.prefixMessages?[...this.prefixMessages,r]:[r]}async _call(e,r){if(this.stop&&r)throw new Error("Stop found in input and default params");let t=this.invocationParams();return t.stop=r??t.stop,(t.stream?await new Promise((a,o)=>{let i,l=!1;this.completionWithRetry({...t,messages:this.formatMessages(e)},{responseType:"stream",onmessage:h=>{if(h.data?.trim?.()==="[DONE]")a(i);else{let c=JSON.parse(h.data);i||(i={id:c.id,object:c.object,created:c.created,model:c.model,choices:[]});let u=c.choices[0];if(u!=null){let d=i.choices.find(m=>m.index===u.index);d||(d={index:u.index,finish_reason:u.finish_reason??void 0},i.choices.push(d)),d.message||(d.message={role:u.delta?.role,content:u.delta?.content??""}),d.message.content+=u.delta?.content??"",this.callbackManager.handleLLMNewToken(u.delta?.content??"",!0)}}}}).catch(h=>{l||(l=!0,o(h))})}):await this.completionWithRetry({...t,messages:this.formatMessages(e)})).choices[0].message?.content??""}async completionWithRetry(e,r){if(!this.client){let t=new nt({...this.clientConfig,baseOptions:{timeout:this.timeout,adapter:x,...this.clientConfig.baseOptions}});this.client=new st(t)}return this.caller.call(this.client.createChatCompletion.bind(this.client),e,r).then(t=>t.data)}_llmType(){return"openai"}}});var Ce={};ce(Ce,{OpenAI:()=>F,OpenAIChat:()=>E,PromptLayerOpenAI:()=>le});import{Configuration as at,OpenAIApi as it}from"/v118/openai@3.2.1/deno/openai.mjs";var F,le,ie=p(()=>{R();we();ae();q();oe();oe();F=class extends M{constructor(e,r){if(e?.modelName?.startsWith("gpt-3.5-turbo")||e?.modelName?.startsWith("gpt-4"))return new E(e,r);super(e??{}),Object.defineProperty(this,"temperature",{enumerable:!0,configurable:!0,writable:!0,value:.7}),Object.defineProperty(this,"maxTokens",{enumerable:!0,configurable:!0,writable:!0,value:256}),Object.defineProperty(this,"topP",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"frequencyPenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"presencePenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"n",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"bestOf",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"logitBias",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelName",{enumerable:!0,configurable:!0,writable:!0,value:"text-davinci-003"}),Object.defineProperty(this,"modelKwargs",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"batchSize",{enumerable:!0,configurable:!0,writable:!0,value:20}),Object.defineProperty(this,"timeout",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stop",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"streaming",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"clientConfig",{enumerable:!0,configurable:!0,writable:!0,value:void 0});let t=e?.openAIApiKey??(typeof __Process$<"u"?__Process$.env.OPENAI_API_KEY:void 0);if(!t)throw new Error("OpenAI API key not found");if(this.modelName=e?.modelName??this.modelName,this.modelKwargs=e?.modelKwargs??{},this.batchSize=e?.batchSize??this.batchSize,this.timeout=e?.timeout,this.temperature=e?.temperature??this.temperature,this.maxTokens=e?.maxTokens??this.maxTokens,this.topP=e?.topP??this.topP,this.frequencyPenalty=e?.frequencyPenalty??this.frequencyPenalty,this.presencePenalty=e?.presencePenalty??this.presencePenalty,this.n=e?.n??this.n,this.bestOf=e?.bestOf??this.bestOf,this.logitBias=e?.logitBias,this.stop=e?.stop,this.streaming=e?.streaming??!1,this.streaming&&this.n>1)throw new Error("Cannot stream results when n > 1");if(this.streaming&&this.bestOf>1)throw new Error("Cannot stream results when bestOf > 1");this.clientConfig={apiKey:t,...r}}invocationParams(){return{model:this.modelName,temperature:this.temperature,max_tokens:this.maxTokens,top_p:this.topP,frequency_penalty:this.frequencyPenalty,presence_penalty:this.presencePenalty,n:this.n,best_of:this.bestOf,logit_bias:this.logitBias,stop:this.stop,stream:this.streaming,...this.modelKwargs}}_identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}identifyingParams(){return this._identifyingParams()}async _generate(e,r){let t=B(e,this.batchSize),s=[],a={};if(this.stop&&r)throw new Error("Stop found in input and default params");let o=this.invocationParams();if(o.stop=r??o.stop,o.max_tokens===-1){if(e.length!==1)throw new Error("max_tokens set to -1 not supported for multiple inputs");o.max_tokens=await Te({prompt:e[0],modelName:this.modelName})}for(let l=0;l<t.length;l+=1){let h=o.stream?await new Promise((m,S)=>{let g={},w,f=!1;this.completionWithRetry({...o,prompt:t[l]},{responseType:"stream",onmessage:b=>{if(b.data?.trim?.()==="[DONE]")m({...w,choices:[g]});else{let P=JSON.parse(b.data);w||(w={id:P.id,object:P.object,created:P.created,model:P.model});let L=P.choices[0];L!=null&&(g.text=(g.text??"")+(L.text??""),g.finish_reason=L.finish_reason,g.logprobs=L.logprobs,this.callbackManager.handleLLMNewToken(L.text??"",!0))}}}).catch(b=>{f||(f=!0,S(b))})}):await this.completionWithRetry({...o,prompt:t[l]});s.push(...h.choices);let{completion_tokens:c,prompt_tokens:u,total_tokens:d}=h.usage??{};c&&(a.completionTokens=(a.completionTokens??0)+c),u&&(a.promptTokens=(a.promptTokens??0)+u),d&&(a.totalTokens=(a.totalTokens??0)+d)}return{generations:B(s,this.n).map(l=>l.map(h=>({text:h.text??"",generationInfo:{finishReason:h.finish_reason,logprobs:h.logprobs}}))),llmOutput:{tokenUsage:a}}}async completionWithRetry(e,r){if(!this.client){let t=new at({...this.clientConfig,baseOptions:{timeout:this.timeout,adapter:x,...this.clientConfig.baseOptions}});this.client=new it(t)}return this.caller.call(this.client.createCompletion.bind(this.client),e,r).then(t=>t.data)}_llmType(){return"openai"}},le=class extends F{constructor(e){if(super(e),Object.defineProperty(this,"promptLayerApiKey",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"plTags",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.plTags=e?.plTags??[],this.promptLayerApiKey=e?.promptLayerApiKey??(typeof __Process$<"u"?__Process$.env.PROMPTLAYER_API_KEY:void 0),!this.promptLayerApiKey)throw new Error("Missing PromptLayer API key")}async completionWithRetry(e,r){if(e.stream)return super.completionWithRetry(e,r);let t=Date.now(),s=await super.completionWithRetry(e),a=Date.now();return await this.caller.call(fetch,"https://api.promptlayer.com/track-request",{method:"POST",headers:{"Content-Type":"application/json",Accept:"application/json"},body:JSON.stringify({function_name:"openai.Completion.create",args:[],kwargs:{engine:e.model,prompt:e.prompt},tags:this.plTags??[],request_response:s,request_start_time:Math.floor(t/1e3),request_end_time:Math.floor(a/1e3),api_key:this.promptLayerApiKey})}),s}}});ie();export{F as OpenAI,E as OpenAIChat,le as PromptLayerOpenAI};
//# sourceMappingURL=openai.js.map